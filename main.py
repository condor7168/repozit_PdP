# -*- coding: utf-8 -*-
import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, callbacks
import pickle
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import io

# Set page config
st.set_page_config(
    page_title="–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main {
        padding: 0rem 1rem;
    }
    .stAlert {
        margin-top: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    </style>
""", unsafe_allow_html=True)

class ApplicantPredictionModel:
    
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.history = None
        self.feature_names = None
    
    def preprocess_data(self, df, is_training=True):
        df = df.copy()
        
        if 'applicant_id' in df.columns:
            df = df.drop('applicant_id', axis=1)
        
        if 'enrolled' in df.columns:
            y = df['enrolled'].values
            X = df.drop('enrolled', axis=1)
        else:
            y = None
            X = df
        
        if is_training:
            self.feature_names = X.columns.tolist()
        
        categorical_cols = X.select_dtypes(include=['object']).columns
        
        for col in categorical_cols:
            if is_training:
                self.label_encoders[col] = LabelEncoder()
                X[col] = self.label_encoders[col].fit_transform(X[col])
            else:
                X[col] = self.label_encoders[col].transform(X[col])
        
        if is_training:
            X_scaled = self.scaler.fit_transform(X)
        else:
            X_scaled = self.scaler.transform(X)
        
        return X_scaled, y
    
    def build_model(self, input_dim):
        model = models.Sequential([
            layers.Input(shape=(input_dim,)),
            layers.Dense(128, activation='relu', name='dense_1'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(64, activation='relu', name='dense_2'),
            layers.BatchNormalization(),
            layers.Dropout(0.2),
            layers.Dense(32, activation='relu', name='dense_3'),
            layers.Dense(1, activation='sigmoid', name='output')
        ])
        
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC()]
        )
        
        self.model = model
        return model
    
    def train_model(self, X_train, y_train, X_val, y_val, epochs=100, batch_size=32, progress_callback=None):
        if self.model is None:
            self.build_model(X_train.shape[1])
        
        early_stop = callbacks.EarlyStopping(
            monitor='val_loss',
            patience=15,
            restore_best_weights=True,
            verbose=0
        )
        
        reduce_lr = callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=0.00001,
            verbose=0
        )
        
        self.history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=[early_stop, reduce_lr],
            verbose=0
        )
        
        return self.history
    
    def evaluate_model(self, X_test, y_test):
        y_pred_proba = self.model.predict(X_test, verbose=0)
        y_pred = (y_pred_proba > 0.5).astype(int).flatten()
        
        accuracy = accuracy_score(y_test, y_pred)
        auc_roc = roc_auc_score(y_test, y_pred_proba)
        
        return {
            'accuracy': accuracy,
            'auc_roc': auc_roc,
            'y_pred': y_pred,
            'y_pred_proba': y_pred_proba,
            'y_test': y_test
        }
    
    def save_model(self, model_path='applicant_model.h5', scaler_path='scaler.pkl'):
        self.model.save(model_path)
        
        preprocessing_data = {
            'scaler': self.scaler,
            'label_encoders': self.label_encoders,
            'feature_names': self.feature_names
        }
        
        with open(scaler_path, 'wb') as f:
            pickle.dump(preprocessing_data, f)
    
    def load_model(self, model_path='applicant_model.h5', scaler_path='scaler.pkl'):
        self.model = keras.models.load_model(model_path)
        
        with open(scaler_path, 'rb') as f:
            preprocessing_data = pickle.load(f)
        
        self.scaler = preprocessing_data['scaler']
        self.label_encoders = preprocessing_data['label_encoders']
        self.feature_names = preprocessing_data['feature_names']
    
    def predict(self, X):
        X_processed, _ = self.preprocess_data(X, is_training=False)
        predictions = self.model.predict(X_processed, verbose=0)
        return (predictions > 0.5).astype(int).flatten(), predictions.flatten()


# Initialize session state
if 'model' not in st.session_state:
    st.session_state.model = ApplicantPredictionModel()
if 'data' not in st.session_state:
    st.session_state.data = None
if 'trained' not in st.session_state:
    st.session_state.trained = False
if 'results' not in st.session_state:
    st.session_state.results = None
if 'current_page' not in st.session_state:
    st.session_state.current_page = "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"

# Header
st.title("üéì –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤")
st.markdown("### –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞—á–∏—Å–ª–µ–Ω–∏—è –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤")
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
    
    st.markdown("### üìã –ù–∞–≤–∏–≥–∞—Ü–∏—è")
    
    if st.button("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", use_container_width=True, 
                 type="primary" if st.session_state.current_page == "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö" else "secondary"):
        st.session_state.current_page = "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
        st.rerun()
    
    if st.button("ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏", use_container_width=True,
                 type="primary" if st.session_state.current_page == "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏" else "secondary"):
        st.session_state.current_page = "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
        st.rerun()
    
    if st.button("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –º–µ—Ç—Ä–∏–∫–∏", use_container_width=True,
                 type="primary" if st.session_state.current_page == "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –º–µ—Ç—Ä–∏–∫–∏" else "secondary"):
        st.session_state.current_page = "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –º–µ—Ç—Ä–∏–∫–∏"
        st.rerun()
    
    if st.button("üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ", use_container_width=True,
                 type="primary" if st.session_state.current_page == "–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ" else "secondary"):
        st.session_state.current_page = "–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ"
        st.rerun()
    
    st.markdown("---")
    
    st.markdown("### üîß –ë—ã—Å—Ç—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—è")
    
    if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", use_container_width=True):
        st.session_state.model = ApplicantPredictionModel()
        st.session_state.data = None
        st.session_state.trained = False
        st.session_state.results = None
        st.session_state.current_page = "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
        st.rerun()
    
    st.markdown("---")
    
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
    
    if st.session_state.data is not None:
        st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(st.session_state.data)} –∑–∞–ø–∏—Å–µ–π")
    else:
        st.info("‚ÑπÔ∏è –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    if st.session_state.trained:
        st.success("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
    else:
        st.info("‚ÑπÔ∏è –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")

# Main content
if st.session_state.current_page == "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö":
    st.header("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
    
    st.subheader("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏")
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª", type=['csv', 'xlsx', 'xls'])
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.session_state.data = df
            st.success(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω! –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
    
    st.markdown("---")
    
    if st.session_state.data is not None:
        st.subheader("üìã –û–±–∑–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞")
        
        tab1, tab2, tab3, tab4 = st.tabs(["üìä –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö", "üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "üé® –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏", "üíæ –°–∫–∞—á–∞—Ç—å"])
        
        with tab1:
            st.dataframe(st.session_state.data, use_container_width=True, height=400)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", len(st.session_state.data))
            with col2:
                st.metric("–ü—Ä–∏–∑–Ω–∞–∫–æ–≤", len(st.session_state.data.columns))
            with col3:
                if 'enrolled' in st.session_state.data.columns:
                    enrolled_count = st.session_state.data['enrolled'].sum()
                    st.metric("–ó–∞—á–∏—Å–ª–µ–Ω–æ", enrolled_count)
            with col4:
                if 'enrolled' in st.session_state.data.columns:
                    not_enrolled = len(st.session_state.data) - enrolled_count
                    st.metric("–ù–µ –∑–∞—á–∏—Å–ª–µ–Ω–æ", not_enrolled)
        
        with tab2:
            st.write("**–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞**")
            st.dataframe(st.session_state.data.describe(), use_container_width=True)
            
            st.write("**–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è**")
            missing = st.session_state.data.isnull().sum()
            if missing.sum() == 0:
                st.success("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!")
            else:
                st.dataframe(missing[missing > 0], use_container_width=True)

        
        with tab3:
            st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö**")
            
            # Numeric columns distribution
            numeric_cols = st.session_state.data.select_dtypes(include=[np.number]).columns.tolist()
            if 'applicant_id' in numeric_cols:
                numeric_cols.remove('applicant_id')
            
            if numeric_cols:
                selected_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è", numeric_cols)
                
                fig = px.histogram(st.session_state.data, x=selected_col, nbins=30, 
                                   title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {selected_col}")
                st.plotly_chart(fig, use_container_width=True)
            
            # Categorical distribution
            if 'enrolled' in st.session_state.data.columns:
                col1, col2 = st.columns(2)
                
                with col1:
                    fig = px.pie(st.session_state.data, names='enrolled', 
                                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞—á–∏—Å–ª–µ–Ω–∏–π',
                                labels={'enrolled': '–°—Ç–∞—Ç—É—Å'})
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    if 'ad_source' in st.session_state.data.columns:
                        source_counts = st.session_state.data['ad_source'].value_counts()
                        fig = px.bar(x=source_counts.index, y=source_counts.values,
                                    title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ä–µ–∫–ª–∞–º—ã',
                                    labels={'x': '–ò—Å—Ç–æ—á–Ω–∏–∫', 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'})
                        st.plotly_chart(fig, use_container_width=True)
        
        with tab4:
            st.write("**–°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç**")
            
            csv = st.session_state.data.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å –∫–∞–∫ CSV",
                data=csv,
                file_name="applicants_data.csv",
                mime="text/csv",
                use_container_width=True
            )

elif st.session_state.current_page == "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏":
    st.header("ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ!")
    else:
        st.subheader("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            epochs = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö", min_value=10, max_value=200, value=50, step=10)
        with col2:
            batch_size = st.selectbox("–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞", [16, 32, 64, 128], index=1)
        with col3:
            test_size = st.slider("–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (%)", min_value=10, max_value=30, value=15, step=5)
        
        st.markdown("---")
        
        if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ", use_container_width=True, type="primary"):
            with st.spinner("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."):
                try:
                    # Preprocess data
                    X, y = st.session_state.model.preprocess_data(st.session_state.data, is_training=True)
                    
                    # Split data
                    X_temp, X_test, y_temp, y_test = train_test_split(
                        X, y, test_size=test_size/100, random_state=42
                    )
                    X_train, X_val, y_train, y_val = train_test_split(
                        X_temp, y_temp, test_size=0.176, random_state=42
                    )
                    
                    # Progress bar
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    status_text.text("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏...")
                    progress_bar.progress(10)
                    
                    # Train model
                    status_text.text("–û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏...")
                    progress_bar.progress(30)
                    
                    history = st.session_state.model.train_model(
                        X_train, y_train, X_val, y_val,
                        epochs=epochs,
                        batch_size=batch_size
                    )
                    
                    progress_bar.progress(80)
                    status_text.text("–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏...")
                    
                    # Evaluate
                    results = st.session_state.model.evaluate_model(X_test, y_test)
                    st.session_state.results = results
                    st.session_state.trained = True
                    
                    progress_bar.progress(100)
                    status_text.text("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                    
                    st.success(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞! –¢–æ—á–Ω–æ—Å—Ç—å: {results['accuracy']*100:.2f}%")
                    
                    # Save model
                    st.session_state.model.save_model()
                    
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
        
        st.markdown("---")
        
        if st.session_state.trained:
            st.subheader("üìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏")
            
            with st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏"):
                buffer = io.StringIO()
                st.session_state.model.model.summary(print_fn=lambda x: buffer.write(x + '\n'))
                st.text(buffer.getvalue())

elif st.session_state.current_page == "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –º–µ—Ç—Ä–∏–∫–∏":
    st.header("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –º–µ—Ç—Ä–∏–∫–∏")
    
    if not st.session_state.trained:
        st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å!")
    else:
        results = st.session_state.results
        
        # Metrics overview
        st.subheader("üéØ –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)",
                f"{results['accuracy']*100:.2f}%",
                delta=f"{(results['accuracy']-0.7)*100:.2f}%" if results['accuracy'] >= 0.7 else None
            )
        
        with col2:
            st.metric("AUC-ROC", f"{results['auc_roc']:.4f}")
        
        with col3:
            precision = (results['y_pred'] == results['y_test']).sum() / len(results['y_pred'])
            st.metric("–¢–æ—á–Ω–æ—Å—Ç—å (Precision)", f"{precision:.4f}")
        
        with col4:
            from sklearn.metrics import recall_score
            recall = recall_score(results['y_test'], results['y_pred'])
            st.metric("–ü–æ–ª–Ω–æ—Ç–∞ (Recall)", f"{recall:.4f}")
        
        st.markdown("---")
        
        # Tabs for different visualizations
        tab1, tab2, tab3, tab4 = st.tabs(["üìä –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è", "üéØ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫", "üìâ ROC-–∫—Ä–∏–≤–∞—è", "üìã –û—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"])
        
        with tab1:
            st.subheader("–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è")
            
            history = st.session_state.model.history.history
            
            # Create subplots
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('–¢–æ—á–Ω–æ—Å—Ç—å', '–ü–æ—Ç–µ—Ä–∏', 'AUC-ROC', 'Precision & Recall')
            )
            
            # Accuracy
            fig.add_trace(
                go.Scatter(y=history['accuracy'], name='–û–±—É—á–µ–Ω–∏–µ', mode='lines'),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(y=history['val_accuracy'], name='–í–∞–ª–∏–¥–∞—Ü–∏—è', mode='lines'),
                row=1, col=1
            )
            
            # Loss
            fig.add_trace(
                go.Scatter(y=history['loss'], name='–û–±—É—á–µ–Ω–∏–µ', mode='lines'),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(y=history['val_loss'], name='–í–∞–ª–∏–¥–∞—Ü–∏—è', mode='lines'),
                row=1, col=2
            )
            
            # AUC
            fig.add_trace(
                go.Scatter(y=history['auc'], name='–û–±—É—á–µ–Ω–∏–µ', mode='lines'),
                row=2, col=1
            )
            fig.add_trace(
                go.Scatter(y=history['val_auc'], name='–í–∞–ª–∏–¥–∞—Ü–∏—è', mode='lines'),
                row=2, col=1
            )
            
            # Precision & Recall
            fig.add_trace(
                go.Scatter(y=history['precision'], name='Precision', mode='lines'),
                row=2, col=2
            )
            fig.add_trace(
                go.Scatter(y=history['recall'], name='Recall', mode='lines'),
                row=2, col=2
            )
            
            fig.update_layout(height=700, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            st.subheader("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
            
            cm = confusion_matrix(results['y_test'], results['y_pred'])
            
            fig = px.imshow(
                cm,
                labels=dict(x="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ", y="–§–∞–∫—Ç–∏—á–µ—Å–∫–∏", color="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"),
                x=['–ù–µ –∑–∞—á–∏—Å–ª–µ–Ω', '–ó–∞—á–∏—Å–ª–µ–Ω'],
                y=['–ù–µ –∑–∞—á–∏—Å–ª–µ–Ω', '–ó–∞—á–∏—Å–ª–µ–Ω'],
                text_auto=True,
                color_continuous_scale='Blues'
            )
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("–ò—Å—Ç–∏–Ω–Ω–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ", cm[0, 0])
                st.metric("–õ–æ–∂–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ", cm[0, 1])
            with col2:
                st.metric("–õ–æ–∂–Ω–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ", cm[1, 0])
                st.metric("–ò—Å—Ç–∏–Ω–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ", cm[1, 1])
        
        with tab3:
            st.subheader("ROC-–∫—Ä–∏–≤–∞—è")
            
            fpr, tpr, thresholds = roc_curve(results['y_test'], results['y_pred_proba'])
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC (AUC = {results["auc_roc"]:.4f})'))
            fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='–°–ª—É—á–∞–π–Ω–∞—è', line=dict(dash='dash')))
            
            fig.update_layout(
                title='ROC-–∫—Ä–∏–≤–∞—è (Receiver Operating Characteristic)',
                xaxis_title='False Positive Rate',
                yaxis_title='True Positive Rate',
                height=500
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with tab4:
            st.subheader("–û—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            
            report = classification_report(
                results['y_test'],
                results['y_pred'],
                target_names=['–ù–µ –∑–∞—á–∏—Å–ª–µ–Ω', '–ó–∞—á–∏—Å–ª–µ–Ω'],
                output_dict=True
            )
            
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df.style.highlight_max(axis=0), use_container_width=True)

elif st.session_state.current_page == "–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ":
    st.header("üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ")
    
    if not st.session_state.trained:
        st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å!")
    else:
        st.subheader("–û–¥–∏–Ω–æ—á–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            age = st.slider("–í–æ–∑—Ä–∞—Å—Ç", 16, 35, 20)
            gender = st.selectbox("–ü–æ–ª", ['M', 'F'])
            region = st.selectbox("–†–µ–≥–∏–æ–Ω", ['Central', 'North-West', 'South', 'Siberia', 'Far-East'])
            exam_score = st.slider("–ë–∞–ª–ª –ï–ì–≠", 30.0, 100.0, 65.0, 0.1)
        
        with col2:
            ad_clicks = st.number_input("–ö–ª–∏–∫–æ–≤ –ø–æ —Ä–µ–∫–ª–∞–º–µ", 0, 50, 3)
            site_visits = st.number_input("–ü–æ—Å–µ—â–µ–Ω–∏–π —Å–∞–π—Ç–∞", 0, 50, 5)
            time_on_site = st.number_input("–í—Ä–µ–º—è –Ω–∞ —Å–∞–π—Ç–µ (–º–∏–Ω—É—Ç—ã)", 0.0, 200.0, 20.0, 0.1)
            ad_source = st.selectbox("–ò—Å—Ç–æ—á–Ω–∏–∫ —Ä–µ–∫–ª–∞–º—ã", ['Yandex', 'Google', 'VK', 'Social'])
        
        if st.button("üîÆ –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑", use_container_width=True, type="primary"):
            input_data = pd.DataFrame({
                'age': [age],
                'gender': [gender],
                'region': [region],
                'exam_score': [exam_score],
                'ad_clicks': [ad_clicks],
                'site_visits': [site_visits],
                'time_on_site': [time_on_site],
                'ad_source': [ad_source]
            })
            
            prediction, probability = st.session_state.model.predict(input_data)
            
            st.markdown("---")
            st.subheader("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if prediction[0] == 1:
                    st.success("### ‚úÖ –ó–ê–ß–ò–°–õ–ï–ù")
                else:
                    st.error("### ‚ùå –ù–ï –ó–ê–ß–ò–°–õ–ï–ù")
            
            with col2:
                st.metric("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–∞—á–∏—Å–ª–µ–Ω–∏—è", f"{probability[0]*100:.2f}%")
            
            # Probability gauge
            fig = go.Figure(go.Indicator(
                mode="gauge+number",
                value=probability[0]*100,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–∞—á–∏—Å–ª–µ–Ω–∏—è"},
                gauge={
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 30], 'color': "lightgray"},
                        {'range': [30, 70], 'color': "gray"},
                        {'range': [70, 100], 'color': "lightgreen"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 50
                    }
                }
            ))
            
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("---")
        
        st.subheader("–ú–∞—Å—Å–æ–≤–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ")
        
        uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è", type=['csv'])
        
        if uploaded_file is not None:
            try:
                df_predict = pd.read_csv(uploaded_file)
                
                st.write("**–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö:**")
                st.dataframe(df_predict.head(), use_container_width=True)
                
                if st.button("üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ", use_container_width=True):
                    predictions, probabilities = st.session_state.model.predict(df_predict)
                    
                    df_predict['–ü—Ä–æ–≥–Ω–æ–∑'] = ['–ó–∞—á–∏—Å–ª–µ–Ω' if p == 1 else '–ù–µ –∑–∞—á–∏—Å–ª–µ–Ω' for p in predictions]
                    df_predict['–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'] = probabilities
                    
                    st.write("**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:**")
                    st.dataframe(df_predict, use_container_width=True)
                    
                    # Download predictions
                    csv = df_predict.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã",
                        data=csv,
                        file_name="predictions.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                    
                    # Summary
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("–í—Å–µ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤", len(predictions))
                    with col2:
                        st.metric("–ü—Ä–æ–≥–Ω–æ–∑: –ó–∞—á–∏—Å–ª–µ–Ω–æ", predictions.sum())
                    
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

# Footer
st.markdown("---")
st.markdown("""
    <div style='text-align: center; color: gray;'>
        <p>–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤ v1.0 | –ù–∞ –±–∞–∑–µ TensorFlow & Streamlit</p>
    </div>
""", unsafe_allow_html=True)
